{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from pymongo import MongoClient\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# rag chain imports\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "\n",
    "import json\n",
    "from duckduckgo_search import DDGS\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "embedding_dim = 768\n",
    "MONGO_DB_URI = os.environ.get('MONGO_DB_URI')\n",
    "GOOGLE_API_KEY = os.environ.get('GEMINI_API_KEY')\n",
    "MONGO_DB_HISTORY = os.environ.get('MONGO_DB_HISTORY')\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(llm, query):\n",
    "    try:\n",
    "        response = llm.generate_content(query.text)\n",
    "        # print(response.text)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(\"Something went wrong in generate_response\")\n",
    "        return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Answer as briefly as you can to the folowing question using the provided Context and Web Results. \n",
    "You are required to give a one-shot answer.\n",
    "\n",
    "<Web Results>{web_results}</Web Results>\n",
    "<Context>{context}</Context>\n",
    "<Question>{question}</Question>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "custom_rag_prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\", \"question\", \"web_results\"]\n",
    ")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "\n",
    "def get_web_results(query):\n",
    "    # print(\"Searching the web for\", query)\n",
    "    try:\n",
    "        results = DDGS().chat(query)  # , model='claude-3-haiku')\n",
    "    except:\n",
    "        results = DDGS().answers(query)\n",
    "\n",
    "    # print(\"The results are\", results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_vector_store(chat_id):\n",
    "    try:\n",
    "        pinecone.create_index(\n",
    "            name=str(chat_id),\n",
    "            dimension=768,\n",
    "            metric=\"cosine\",\n",
    "            spec=ServerlessSpec(\n",
    "                cloud=\"aws\",\n",
    "                region=\"us-east-1\")\n",
    "        )\n",
    "    except:\n",
    "        pass\n",
    "    pinecone_index = pinecone.Index(str(chat_id))\n",
    "\n",
    "    vector_store = PineconeVectorStore(\n",
    "        index=pinecone_index,\n",
    "        embedding=GoogleGenerativeAIEmbeddings(\n",
    "            google_api_key=GOOGLE_API_KEY,\n",
    "            model=\"models/text-embedding-004\",\n",
    "            task_type=\"clustering\"\n",
    "        )\n",
    "    )\n",
    "    return vector_store\n",
    "\n",
    "def generate_file_hash(file_path):\n",
    "    sha256 = hashlib.sha256()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        while chunk := f.read(8192):\n",
    "            sha256.update(chunk)\n",
    "    return sha256.hexdigest()\n",
    "\n",
    "\n",
    "def chunk_and_store(file_path, chat_id):\n",
    "    try:\n",
    "        # Initialize Pinecone index and vector store\n",
    "        vector_store = initialize_vector_store(chat_id)\n",
    "\n",
    "        file_hash = generate_file_hash(file_path)\n",
    "\n",
    "        # Load and split the document\n",
    "        loader = PyMuPDFLoader(file_path)\n",
    "        documents = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000, chunk_overlap=300)\n",
    "        chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "        # Insert document chunks with unique IDs and file path metadata\n",
    "        uuids = [str(file_hash)+str(i) for i in range(len(chunks))]\n",
    "\n",
    "        vector_store.add_documents(documents=chunks, ids=uuids)\n",
    "\n",
    "        return \"Documents successfully embedded and stored in Pinecone.\"\n",
    "    except Exception as e:\n",
    "        # print(\"Exception thrown:\", e)\n",
    "        return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response_with_rag(llm, query, chat_id):\n",
    "    try:\n",
    "        vector_store = initialize_vector_store(chat_id)\n",
    "        retriever = vector_store.as_retriever(\n",
    "            search_type=\"similarity_score_threshold\",\n",
    "            search_kwargs={\"k\": 5, \"score_threshold\": 0.5},\n",
    "        )\n",
    "\n",
    "        rag_chain = (\n",
    "            {\"context\": retriever | format_docs,\n",
    "             \"question\": RunnablePassthrough(), \n",
    "             \"web_results\": RunnableLambda(lambda x: get_web_results(x)),\n",
    "             }\n",
    "            | custom_rag_prompt\n",
    "            | RunnableLambda(lambda x: generate_response(llm, x))\n",
    "            # | StrOutputParser\n",
    "        )\n",
    "\n",
    "        prompt = custom_rag_prompt.format(\n",
    "            context = format_docs(retriever.invoke(query)[:30]),\n",
    "            question = query, \n",
    "            web_results = get_web_results(query),\n",
    "        )\n",
    "\n",
    "        result = rag_chain.invoke(query)\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in generate_response_with_rag: {e}\")\n",
    "        return f\"Error in generate_response_with_rag: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add RAG documents to vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = r\"C:\\Users\\shaharyar\\Documents\\VS Code\\Topics in LLMs\\Project\\harrypotter.pdf\"\n",
    "# CHAT_ID = \"eval-default\"\n",
    "CHAT_ID = \"eval-clustering\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use CHAT_ID `eval-default` for the default embedding and `eval-clustering` for clustered embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "\n",
    "# # Suppress warnings\n",
    "# with warnings.catch_warnings():\n",
    "#     warnings.simplefilter(\"ignore\")\n",
    "#     chunk_and_store(FILE_PATH, CHAT_ID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def get_result(question):\n",
    "    return generate_response_with_rag(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = genai.GenerativeModel(\"models/gemini-1.5-flash-8b-latest\",\n",
    "                            generation_config={\n",
    "                                \"temperature\": 0,\n",
    "                                \"response_mime_type\": \"text/plain\"}\n",
    "                            )\n",
    "\n",
    "model2 = genai.GenerativeModel(\"models/gemini-2.0-flash-exp\",\n",
    "                            generation_config={\n",
    "                                \"temperature\": 0,\n",
    "                                \"response_mime_type\": \"text/plain\"}\n",
    "                            )\n",
    "\n",
    "model3 = genai.GenerativeModel(\"models/learnlm-1.5-pro-experimental\",\n",
    "                            generation_config={\n",
    "                                \"temperature\": 0,\n",
    "                                \"response_mime_type\": \"text/plain\"}\n",
    "                            )\n",
    "\n",
    "models = [model1, model2, model3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who was the founder of Ravenclaw House?</td>\n",
       "      <td>Rowena Ravenclaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the name of the spell used to create a...</td>\n",
       "      <td>Protego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What was Elfric the Eager's uprising?</td>\n",
       "      <td>A revolt.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the name of the spell used to create a...</td>\n",
       "      <td>Furnunculus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the name of the spell used to repair o...</td>\n",
       "      <td>Reparo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question            answer\n",
       "0            Who was the founder of Ravenclaw House?  Rowena Ravenclaw\n",
       "1  What is the name of the spell used to create a...           Protego\n",
       "2              What was Elfric the Eager's uprising?         A revolt.\n",
       "3  What is the name of the spell used to create a...       Furnunculus\n",
       "4  What is the name of the spell used to repair o...            Reparo"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('harry-potter-trivia-ai-100.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who was the founder of Ravenclaw House?</td>\n",
       "      <td>Rowena Ravenclaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the name of the spell used to create a...</td>\n",
       "      <td>Protego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What was Elfric the Eager's uprising?</td>\n",
       "      <td>A revolt.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the name of the spell used to create a...</td>\n",
       "      <td>Furnunculus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the name of the spell used to repair o...</td>\n",
       "      <td>Reparo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question            answer\n",
       "0            Who was the founder of Ravenclaw House?  Rowena Ravenclaw\n",
       "1  What is the name of the spell used to create a...           Protego\n",
       "2              What was Elfric the Eager's uprising?         A revolt.\n",
       "3  What is the name of the spell used to create a...       Furnunculus\n",
       "4  What is the name of the spell used to repair o...            Reparo"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df.sample(5)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def generate_results_for_all_models(df, chat_id):\n",
    "    # Initialize empty lists to store responses for each model\n",
    "    model_1_responses = []\n",
    "    model_2_responses = []\n",
    "    model_3_responses = []\n",
    "\n",
    "    # Iterate over each question with a tqdm progress bar\n",
    "    for question in tqdm(df['question'], desc=\"Generating responses\", unit=\"question\"):\n",
    "        # print(question)\n",
    "        try:\n",
    "            # Get response for Model 1\n",
    "            response_model_1 = generate_response_with_rag(models[0], question, chat_id)            \n",
    "        except Exception as e:\n",
    "            response_model_1 = f\"Error: {e}\"\n",
    "\n",
    "        try:\n",
    "            # Get response for Model 2\n",
    "            response_model_2 = generate_response_with_rag(models[1], question, chat_id)\n",
    "        except Exception as e:\n",
    "            response_model_2 = f\"Error: {e}\"\n",
    "\n",
    "        try:\n",
    "            # Get response for Model 3\n",
    "            response_model_3 = generate_response_with_rag(models[2], question, chat_id)\n",
    "        except Exception as e:\n",
    "            response_model_3 = f\"Error: {e}\"\n",
    "\n",
    "        # Append responses to their respective lists\n",
    "        response_model_1 = response_model_1.replace('\\n', ' ')\n",
    "        response_model_2 = response_model_2.replace('\\n', ' ')\n",
    "        response_model_3 = response_model_3.replace('\\n', ' ')\n",
    "\n",
    "        model_1_responses.append(response_model_1)\n",
    "        model_2_responses.append(response_model_2)\n",
    "        model_3_responses.append(response_model_3)\n",
    "\n",
    "    # Add responses as new columns to the DataFrame\n",
    "    df['gemini_1.5_flash'] = model_1_responses\n",
    "    df['gemini_2.0_flash'] = model_2_responses\n",
    "    df['learnlm_1.5_flash'] = model_3_responses\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  50%|█████     | 50/100 [26:41<26:04, 31.30s/question]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something went wrong in generate_response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  67%|██████▋   | 67/100 [40:16<20:05, 36.54s/question]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something went wrong in generate_response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  68%|██████▊   | 68/100 [40:48<18:49, 35.29s/question]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something went wrong in generate_response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses: 100%|██████████| 100/100 [1:00:28<00:00, 36.28s/question]\n"
     ]
    }
   ],
   "source": [
    "# Apply the function and display the updated DataFrame\n",
    "df = generate_results_for_all_models(df, CHAT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>gemini_1.5_flash</th>\n",
       "      <th>gemini_2.0_flash</th>\n",
       "      <th>learnlm_1.5_flash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who was the founder of Ravenclaw House?</td>\n",
       "      <td>Rowena Ravenclaw</td>\n",
       "      <td>Rowena Ravenclaw</td>\n",
       "      <td>Rowena Ravenclaw was the founder of Ravenclaw ...</td>\n",
       "      <td>Rowena Ravenclaw.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the name of the spell used to create a...</td>\n",
       "      <td>Protego</td>\n",
       "      <td>Shield Charm</td>\n",
       "      <td>The Shield Charm.</td>\n",
       "      <td>Shield Charm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What was Elfric the Eager's uprising?</td>\n",
       "      <td>A revolt.</td>\n",
       "      <td>The provided text does not contain information...</td>\n",
       "      <td>The provided text does not mention Elfric the ...</td>\n",
       "      <td>This question cannot be answered from the give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the name of the spell used to create a...</td>\n",
       "      <td>Furnunculus</td>\n",
       "      <td>Fiendfyre</td>\n",
       "      <td>The spell used to create the fire is called Fi...</td>\n",
       "      <td>Fiendfyre.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the name of the spell used to repair o...</td>\n",
       "      <td>Reparo</td>\n",
       "      <td>Reparo</td>\n",
       "      <td>Reparo</td>\n",
       "      <td>Reparo.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question            answer  \\\n",
       "0            Who was the founder of Ravenclaw House?  Rowena Ravenclaw   \n",
       "1  What is the name of the spell used to create a...           Protego   \n",
       "2              What was Elfric the Eager's uprising?         A revolt.   \n",
       "3  What is the name of the spell used to create a...       Furnunculus   \n",
       "4  What is the name of the spell used to repair o...            Reparo   \n",
       "\n",
       "                                    gemini_1.5_flash  \\\n",
       "0                                  Rowena Ravenclaw    \n",
       "1                                      Shield Charm    \n",
       "2  The provided text does not contain information...   \n",
       "3                                         Fiendfyre    \n",
       "4                                            Reparo    \n",
       "\n",
       "                                    gemini_2.0_flash  \\\n",
       "0  Rowena Ravenclaw was the founder of Ravenclaw ...   \n",
       "1                                 The Shield Charm.    \n",
       "2  The provided text does not mention Elfric the ...   \n",
       "3  The spell used to create the fire is called Fi...   \n",
       "4                                            Reparo    \n",
       "\n",
       "                                   learnlm_1.5_flash  \n",
       "0                                 Rowena Ravenclaw.   \n",
       "1                                     Shield Charm.   \n",
       "2  This question cannot be answered from the give...  \n",
       "3                                        Fiendfyre.   \n",
       "4                                           Reparo.   "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('harry-potter-trivia-ai-100-results-clustering.csv', index=False)\n",
    "# df.to_csv('harry-potter-trivia-ai-100-results-default.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
